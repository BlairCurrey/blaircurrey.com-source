---
layout: _layouts/post.njk
title: Revisiting an Old Project
tags: [posts, code-review, optimization, python]
---

In the fall of 2019 I finished the first semester of my computer science degree. Armed with the facts of *Intro to Programming I* and the basics of python I started on my first self-guided programming project — procedurally generated images of lakes using Perlin noise. The project worked, but as you can probably guess, it wasn't pretty. <!-- excerpt --> 

The code that is. I was pleased with the lakes.

![Lake](/img/posts/1-lake1.jpg)

Two years later I have finished *Object-Oriented Programming*, *Data Structures and Algorithms I & II*, and revisited  this project from a new vantage point. I will detail the original state of the program's structure and runtime, analyze the problematic areas and share my solutions. For more background information on the project and to see the improved version you can visit the [GitHub repository here](https://github.com/BlairCurrey/lake-generator).

It's been a long time since I worked on this program so I began by asking myself:

### What is the program doing?
 
- Sets a bunch of global parameters (image size, noise parameters, etc).
- loads filter, sets to grayscale, and normalizes range
- makes noise matrix. for each pixel:
    - generates a noise value from global parameters
    - applies filter
    - generates and adds more noise to current pixel's value 4 more     times *(why??)*
- constrains matrix to range between 0.0 and 1.0
- adds land bias
- translates each pixel's value to an RGB value
- makes image from matrix, shows, saves

You can see the entirety of this version [in this GitHub gist](https://gist.github.com/BlairCurrey/b944c14c900a4c7f996ecbb463f0d3a3). Although it's not pretty, I was very inexperienced at the time and remember how challenging it was. I was quite pleased to simply produce something that did what I intended, as slow and hacked together as it was.

### Main Conclusions

- I loop through the matrix using nested for-loops 3 times. NumPy's much faster array methods could be used instead in some places.
- Not user friendly. Some functionality is turned off/on by commenting and settings are defined within the script. Customizable settings should be exposed to the user and input into our map making object.
- No encapsulation. The program can be refactored into a few classes
- Inconsistent style and bad practices. `filter` class shares the name with the `filter` keyword, unused variables, cryptic or inconsistently named variables, etc. What does `refine_world` do?


### Plan

I wanted to focus on optimizing speed first since I needed to run the program frequently to test my changes. I quickly refactored everything into one `noiseMap` class before focusing on the runtime. It's worth noting that most of the improvements came simply from making better use of NumPy, rather than some novel or complicated solution.

After improving the runtime, I could go back and refactor this monolithic class. This would make it easier for me to improve functionality, such as letting the user define the configuration variables in a separate file.

### Methodology for Measuring Runtime

Initially I thought about doing an asymptotic analysis but realized this would not be an effective way of measuring the difference. Stack Overflow user *hpaulj* explains it better than I can [in this answer,](https://stackoverflow.com/questions/52201990/is-there-a-list-of-big-o-complexities-for-the-numpy-library) where he says:

>BigO complexity is not often used with Python and numpy. It's a measure of how the code scales with problem size. That's useful in a compiled language like C. But here the code is a mix of interpreted Python and compiled code. Both can have the same bigO, but the interpreted version will be orders of magnitude slower. That's why most of the SO questions about improving numpy speed, talk about 'removing loops' and 'vectorizing'.

In our case we replace looping over the matrix in python with NumPy's methods, which also traverse each element. In terms of how they scale with input size (matrix height and width) they are completely equal. However, the NumPy implementation should be much faster in real time, so asymptotic analysis wouldn't capture the difference. 

I measured the time with [cProfiler](https://docs.python.org/3.8/library/profile.html) instead. While time measurements are inexact, the execution time of the original code is large enough that this imprecision does not cloud comparisons with the runtime of the improved code. Still, it's worth noting that identical functions vary in runtime across executions.

Here are the baseline results, filtered to show the most relevant bits:

<div class="table-responsive">

|  Calls  | Time    |  Per Call   | Cumulative Time |        filename:lineno(function)       |
|:-------:|:-------:|:-------:|:-------:|:--------------------------------------:|
|    1    |  0.001  |  0.001  |  35.081 | mapGen. py:23(\_\_init\_\_)                 |
|    1    |  13.865 |  13.865 |  26.841 | mapGen. py:52(make_noise)               |
| 8388608 |  12.976 |  0.000  |  12.976 | {built-in method noise._perlin.noise3} |
|    1    |  4.969  |  4.969  |  4.969  | mapGen. py:101(add_color)               |
|    1    |  1.529  |  1.529  |  1.529  | {built-in method nt.system}            |
|    1    |  1.489  |  1.489  |  1.489  | mapGen. py:94(refine_world)        {<.table >}|

</div>

This shows the cumulative time to run the program was 35.081 seconds. Most of this comes from `make_noise` (26.841 seconds), which includes the pnoise function, with another chunk from `add_color` (4.969 seconds) and `refine_world` (1.489). The "built-in" methods are from imported modules, so they cannot be improved in my code. Let's take a look at these functions.

### `make_noise`
<script src="https://gist.github.com/BlairCurrey/aef90cd870cfdeaea750d21a29dd567c.js"></script>

In this function, we are creating an array full of zeroes then traversing through the height and width (`shape[0]` and `shape[1]`), which in this case is 1024 x 2048. For each of these positions, we are generating a noise value (line 10), subtracting the corresponding filter value (line 20), and then iterating 4 more times and adding more noise values (line 23). Thus, we call the pnoise.noise3 function 1024 x 2048 x 4 = 8,388,608 times, as seen in row 3 of our profiler result above.

First, I wanted to see what the innermost loop was doing. We are already creating noise values and then subtracting our filter, so what difference does it make? It makes this function's runtime 4 times longer, so it better be important.

The first picture results from including the additional noise, followed by a picture from the same seed that omits it.

<div class="row">
    <div class="column col-lg-6 col-sm-12">
        <img src="/img/posts/1-map-extra-noise.jpg"></img>
    </div>
    <div class="column col-lg-6 col-sm-12">
        <img src="/img/posts/1-map-no-extra.jpg"></img>
    </div>
</div>

I see very little difference. The computationally cheaper one certainly looks valid. I tried it on a few more images and the results were similar. The additional noise values provided a bit more randomness to the boundaries defined by our filter, but we already have a weight that we can apply to our filters to reduce their influence. In addition, they often broke the lake by extending the water to the edge of the image, sometimes even more dramatically than the provided example. It wasn't valuable, so I was happy to cut it and reran the profiler.

<div class="table-responsive">

|  Original Time  |  New Time  |  filename:lineno(function)             |
|:---------------:|:----------:|:--------------------------------------:|
|     26.841      |    6.942   |  mapGen. py:52(make_noise)   {<.table>}|

</div>

This isn't an optimization so much as simply omitting  work, but it was appreciated nonetheless. As expected, it made the function about 4 times faster.

In addition to this change, I realized that I could apply the filter outside of this large nested loop using NumPy's subtract method instead. That is, instead of:

<script src="https://gist.github.com/BlairCurrey/f6b63abc76b05551b6a39647928bda60.js"></script>

I could do something like:

<script src="https://gist.github.com/BlairCurrey/dfec95702d1cb0fa5af1df157d0b250c.js"></script>

 This meant less work inside our large nested for-loop in python and taking better advantage of NumPy's speed, which can be seen in the new profiler results for `make_noise`:

<div class="table-responsive">

|  Previous Time  |  New Time  |  filename:lineno(function)             |
|:---------------:|:----------:|:--------------------------------------:|
|     6.942      |    3.975   |  mapGen. py:52(make_noise)   {<.table>}|

</div>

### `refine_world`

<script src="https://gist.github.com/BlairCurrey/4f76f651adfd6d9caa592e6891751c4b.js"></script>

This loops through our matrix again (2,097,152 iterations given a size of 1024 x 2048) to factor in `land_bias`. Considering `land_bias` can be 0 — and often will since that is the default — there is no reason to always perform this function. So the first improvement that we can make is to only adjust for `land_bias` if it is not 0. So in many cases, the 1.489 seconds we observed in our test would be reduced to 0.

As for improving the runtime when we actually set the bias, my first instinct was to utilize the first nested for-loop we already invested in inside `make_noise`, but there is a reason we didn't do this in the first place. `refine_world` occurs after our matrix is normalized to a new range between 0.0 and 1.0. There is no way for us to know the actual range of our noise values before they are all set, so adjusting the values in `make_noise` would lead to inconsistent results. Fortunately, there is a better solution anyway.

Again, I missed a much simpler and faster NumPy solution. We can use operators on NumPy arrays to adjust each value instead. After some additional refactoring and adding the `land_bias` check, the code once in `refine_world` has been reduced to:

<script src="https://gist.github.com/BlairCurrey/a2e01be302f46bc14c7d883f8065b5ae.js"></script>

The runtime for this piece of code shows that even in scenarios where `land_bias` is not 0, not only does it run faster than all scenarios in the original implementation, but it hardly takes any time all:

<div class="table-responsive">

|  Original Time  |  New Time  |  filename:lineno(function)             |
|:---------------:|:----------:|:--------------------------------------:|
|      1.489      |    0.003   |  mapGen. py:94(refine_world)   {<.table>}|

</div>

### `add_color`

<script src="https://gist.github.com/BlairCurrey/c44278ec3cc7faeb4275f18ea5711d0c.js"></script>

Once again, we are looping through the entire matrix. This time we are evaluating each pixel and assigning it an RGB value based on the range it falls in.

In this case we can make use of [NumPy's Boolean array indexing](https://numpy.org/devdocs/reference/arrays.indexing.html). Boolean array indexing is a feature of the NumPy array data structure that allows us to select all values of an array that meet certain conditions. After some additional refactoring and converting to Boolean indexing, I was able to get rid of the nested for-loop and the if statements turned into:

<script src="https://gist.github.com/BlairCurrey/bfa3f5e76754da1e4f44188d3515397c.js"></script>

Similar to our `refine_world` improvements, this drastically reduced runtime.

<div class="table-responsive">

|  Original Time  |  New Time  |  filename:lineno(function)             |
|:---------------:|:----------:|:--------------------------------------:|
|      4.969      |    0.133   |  mapGen. py:101(add_color)   {<.table>}|

</div>

After these optimizations, I returned to refactoring everything into objects and extending their functionality to support the use of a configuration file. A user can define Perlin noise settings, filters, and save options in the config.ini file. [More details on these settings can be found in the documentation here.](https://github.com/BlairCurrey/lake-generator/blob/master/src/Config.py) This file is read and transformed by a `Config` object, which we can use to create a `World` object. The `World` object creates and transforms the matrix according to the configuration, which also informs our World object what to do when we invoke the save method. Instead of executing a script with everything in it, we can just run the `main.py` file to generate and save an image. 

<script src="https://gist.github.com/BlairCurrey/fedfa079ec1f4e84121cb06111956552.js"></script>

This `World` object makes use of our `Filter` class and creates a `Stats` object where we can collect and store the unique details of our generated lake. These classes can be found in full [here](https://github.com/BlairCurrey/lake-generator/tree/master/src).

### Final Runtime Results

After refactoring and optimizing I ran the profiler a final time.

<div class="table-responsive">

|  Calls  | Time    |  Per Call   | Cumulative Time | filename:lineno(function)  |
|:-------:|:-------:|:-------:|:-------:|:--------------------------------------:|
|    1    |  0.001  |  0.001  |  4.039  | World. py:14(\_\_init\_\_)             |
|    1    |  0.003  |  0.003  |  3.877  | World. py:22(__get_height_matrix)      |
|    1    |  1.004  |  1.004  |  3.765  | World. py:37(__get_noise)              |
| 2097152 |  2.761  |  0.000  |  2.761  | {built-in method noise._perlin.noise3} |
|    1    |  0.132  |  0.132  |  0.132  | World. py:81(__get_rgb_matrix)         |
|    1    |  1.607  |  1.607  |  1.607  | {built-in method nt.system}            |
|    1    |  0.019  |  0.019  |  0.019  | World. py:63(__get_filtered_and_constrained) {<.table >}|


</div>

### Conclusions and Further Improvements

Most of the running time came from 3 nested for-loops. We eliminated 2 of these and reduced the number of iterations of the third by 75%. I was able to accomplish this by leveraging NumPy's built-in functions and operators and eliminating non-value-added work. Overall, the program runs almost 90% faster (from 35s to 4s), but there is still room for improvement.

In particular, I could use a [vectorized implementation of Perlin noise](https://github.com/pvigier/perlin-numpy) instead of the noise library. This would require significant refactoring and I may not be able to tweak all the settings as I am doing with the current library (which I find fun). This would probably be the largest improvement to the execution time by a wide margin.

As for the structure and functionality, some variables are still hard-coded, although they are at least more appropriately defined in our `Config` class. In particular, it would be nice to make the image size scalable. All the filters are set to a certain size and would need to be resized. This could be implemented in our `Filter` class when we make the array of values from an image. This demonstrates how encapsulating all logic and data related to unique aspects (in this case, filters) makes our program easier to extend.